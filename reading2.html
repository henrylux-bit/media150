<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="author" content="Henry Downes">
    <title>Reading 1</title>
    <link rel="stylesheet" href="style.css">    

</head>
<body>
    <header>
<nav>
    <ul>   
         <li><a href="index.html">Home</a></li>
         <li><a href="reading1.html">Reading 1</a></li>
         <li><a href="hw1.html">Homework 2</a></li>
         <li><a href="reading2.html">Reading 2</a></li>
         <li><a href="dof.html">Depth of Field exercise</a></li>
         <li><a href="field_blur.html">Filed Blur exercise</a></li>
         <li><a href="camera_raw.html">Camera Raw Fix</a></li>
    </ul>
</nav>
<hr>
<h1>Henry Downes, Lab 6</h1>
    </header>
<h2>Reading Two</h2>
<p>
     Today it feels almost impossible to scroll online without seeing images that look real but may not 
     exist at all. Social media feeds are filled with hyper‑real videos, AI‑generated influencers, political 
     memes, and scenes that blur the line between something real and something out of this world. At first, 
     many of these images seem real, even impressive. Some videos recreate anime worlds with realistic actors, 
     choreography, and lighting in ways that required an entire team of artists. The images are so convincing 
     that they make me pause and question what might be changing about how we create, see, and trust images, 
     and what that shift could mean for artists and viewers like me.
</p>
<p>
     Through studying photography, I have learned to think about how images are made. Lighting, 
     composition, editing, and timing all shape how a viewer understands a photograph. Even before AI‑generated 
     images, photographs were never completely documentation of an event, time, or space. They were 
     interpretations of reality created by a person behind the camera. Photographers can edit an image through 
     digital programs, chemical reactions, the use of different materials, dodging and burning, or even by 
     creating an entirely new scene through compositing images using digital or analog processes. Because 
     photographs and films are shaped through many choices, Malik’s text about “AI slop” felt like an extension 
     of something that has always existed in visual culture. Malik suggests that the spread of AI content will 
     make it difficult to tell the difference between fact and fiction.
</p>
<p>
     Online, I have seen hyper‑realistic AI videos, fake influencer accounts, and AI‑generated political imagery. 
     It is incredible how fast this technology has grown, but it is also unsettling. In a short time, AI has 
     moved from the overhyped and poor results of 2022 to something that can easily blend into today's media. Today 
     I see more advertisements made with generative AI, such as a Coca‑Cola commercial, ads from Skechers and 
     MetroPCS, and even on flyers from a local sandwich shop in my neighborhood. This shows how easily creative work 
     could be replaced.
</p>
<p>
     AI can clearly be dangerous when used to manipulate, misinform, or exploit people who cannot easily tell the 
     difference between real and generated content. At the same time, artificial intelligence also has positive potential 
     in areas such as science, education, and problem‑solving. One such example is
     <a 
         href="https://pmc.ncbi.nlm.nih.gov/articles/PMC11589127/" 
         target="_blank"
         >Google receiving a Nobel Prize in 2024 for solving a 50‑year‑old protein‑folding problem.
     </a>
     I believe the issue may not be the technology itself, but what it reveals about how society already interacts with images.

</p>
<p>
     The internet has always allowed people to display idealized versions of themselves and their beliefs, but now AI has 
     removed many of the barriers that required skill, time, or resources. Almost anyone can instantly create images that 
     reflect what they want to believe. Algorithms then reinforce these ideas. Over time, this may create personalized visual 
     worlds where individuals rarely encounter perspectives outside their own.
</p>
<p>
     From my perspective, AI is like an accelerant dropped into the mix of visual culture. This technology has improved so 
     quickly that we, as a society, have not had time to adjust to it. The unsettling feeling may come from the idea that we 
     gravitate toward images that comfort, entertain, or validate us, even when those things are further away from reality.
</p>
<p>
     The novelty of asking one another whether something is real or fake will eventually wear off, and we will begin asking 
     different questions such as: why was it made, and what does it reflect about our society? This technology was released to 
     the public for “free,” giving nearly everyone access to it. But this leads to another question: how do we learn to coexist 
     with AI in a productive and responsible way?
</p>

</body>
</html>